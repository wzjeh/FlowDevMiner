import os
import sys
import pandas as pd
import numpy as np
from typing import List, Dict, Set, Tuple, Any

# å¼ºåˆ¶æ·»åŠ å½“å‰ç›®å½•åˆ° sys.pathï¼Œç¡®ä¿èƒ½å¯¼å…¥åŒç›®å½•æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

try:
    from evaluate_results import (
        METHODS, 
        list_document_ids, 
        load_ground_truth, 
        load_prediction, 
        flatten_items, 
        compute_counts,
        compute_metrics
    )
except ImportError as e:
    print(f"Import Error: {e}")
    sys.exit(1)

print("Successfully imported evaluate_results", flush=True)

# å®šä¹‰å­—æ®µæ‰€å±çš„èƒ½åŠ›ç±»åˆ«
CATEGORY_MAP = {
    "struct": "1. Instruction Following (JSON Skeleton)",
    "reaction_type": "2. Reaction Type",
    "reactant.name": "3. Reactants",
    "reactant.role": "3. Reactants",
    "product.name": "4. Products",
    "condition": "5. Conditions",
    "reactor.type": "6. Reactor",
    "reactor.inner_diameter": "6. Reactor",
    "metrics.conversion": "7. Metrics",
    "metrics.yield": "7. Metrics",
    "metrics.selectivity": "7. Metrics",
    "metrics.unit": "7. Metrics"
}

def categorize_item(item: Tuple) -> str:
    """æ ¹æ® tuple çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆkeyï¼‰è¿”å›å…¶æ‰€å±çš„ç±»åˆ«"""
    key = item[0]
    return CATEGORY_MAP.get(key, "8. Others")

def analyze_method_detailed(method: str, doc_ids: List[str]) -> pd.DataFrame:
    """
    è®¡ç®—æŸæ–¹æ³•åœ¨ä¸åŒç±»åˆ«ä¸‹çš„ TP/FP/FN ç»Ÿè®¡
    """
    # å­˜å‚¨ç´¯ç§¯è®¡æ•°ï¼šcounts[category] = {'tp': 0, 'fp': 0, 'fn': 0}
    counts = {cat: {'tp': 0, 'fp': 0, 'fn': 0} for cat in set(CATEGORY_MAP.values())}
    
    for doc_id in doc_ids:
        gt = load_ground_truth(doc_id)
        if gt is None:
            continue
        pred = load_prediction(method, doc_id)
        
        if pred is None:
            # å…¨ FN
            gt_items = flatten_items(gt)
            for item in gt_items:
                cat = categorize_item(item)
                counts[cat]['fn'] += 1
        else:
            gt_items = flatten_items(gt)
            pred_items = flatten_items(pred)
            
            # æŒ‰ç±»åˆ«æ‹†åˆ†é›†åˆ
            gt_by_cat = {cat: set() for cat in counts}
            pred_by_cat = {cat: set() for cat in counts}
            
            for item in gt_items:
                gt_by_cat[categorize_item(item)].add(item)
            for item in pred_items:
                pred_by_cat[categorize_item(item)].add(item)
                
            for cat in counts:
                tp, fp, fn = compute_counts(gt_by_cat[cat], pred_by_cat[cat])
                counts[cat]['tp'] += tp
                counts[cat]['fp'] += fp
                counts[cat]['fn'] += fn

    # è½¬æ¢ä¸º DataFrame
    data = []
    for cat, metrics in counts.items():
        m = compute_metrics(metrics['tp'], metrics['fp'], metrics['fn'])
        data.append({
            "Method": method,
            "Category": cat,
            "Precision": m['precision'],
            "Recall": m['recall'],
            "F1": m['f1'],
            "Support": metrics['tp'] + metrics['fn']
        })
    
    return pd.DataFrame(data)

def generate_diagnosis_report(df: pd.DataFrame):
    """
    ç”Ÿæˆä¸‰æ–¹å¯¹æ¯”æŠ¥å‘Š: Qwen3 vs Local Finetuned vs Local Unfinetuned
    """
    print(f"\n{'='*30} æ·±åº¦è¯Šæ–­æŠ¥å‘Š: ä¸‰æ–¹æ¨ªå‘å¯¹æ¯” {'='*30}")
    
    # è·å–å„æ–¹æ³•çš„æ•°æ®
    qwen_df = df[df['Method'] == "qwen3"].set_index('Category')
    ft_df = df[df['Method'] == "local llm finetuned"].set_index('Category')
    unft_df = df[df['Method'] == "local llm unfinetuned"].set_index('Category')
    
    cats = sorted(list(set(qwen_df.index) | set(ft_df.index) | set(unft_df.index)))
    
    print(f"\n{'Category':<40} | {'Qwen3':<8} | {'Local FT':<8} | {'Local UnFT':<10} | {'FT vs UnFT':<10} | {'FT vs Qwen':<10}")
    print("-" * 110)
    
    improvements = []
    regressions = []
    
    for cat in cats:
        q_f1 = qwen_df.loc[cat, 'F1'] if cat in qwen_df.index else 0.0
        ft_f1 = ft_df.loc[cat, 'F1'] if cat in ft_df.index else 0.0
        unft_f1 = unft_df.loc[cat, 'F1'] if cat in unft_df.index else 0.0
        
        diff_ft_unft = ft_f1 - unft_f1
        diff_ft_qwen = ft_f1 - q_f1
        
        print(f"{cat:<40} | {q_f1:.4f}   | {ft_f1:.4f}   | {unft_f1:.4f}     | {diff_ft_unft:+.2f}       | {diff_ft_qwen:+.2f}")
        
        if diff_ft_unft > 0.05:
            improvements.append(f"- {cat}: å¾®è°ƒæå‡äº† {diff_ft_unft*100:.1f}%")
        elif diff_ft_unft < -0.05:
            regressions.append(f"- {cat}: å¾®è°ƒå¯¼è‡´å€’é€€äº† {abs(diff_ft_unft)*100:.1f}%")

    print("\n>>> å¾®è°ƒæ•ˆæœåˆ†æ (Impact of Finetuning):")
    if improvements:
        print("âœ… æ˜¾è‘—æå‡çš„é¢†åŸŸ:")
        for i in improvements:
            print(i)
    else:
        print("âš ï¸ å¾®è°ƒæœªå¸¦æ¥æ˜¾è‘—æå‡ã€‚")
        
    if regressions:
        print("\nâŒ å‡ºç°å€’é€€çš„é¢†åŸŸ (éœ€æ£€æŸ¥è¿‡æ‹Ÿåˆ/é—å¿˜):")
        for r in regressions:
            print(r)
            
    print("\n>>> è·ç¦»å•†ç”¨æ¨¡å‹å·®è· (Gap to Qwen3):")
    gaps = []
    for cat in cats:
        q_f1 = qwen_df.loc[cat, 'F1'] if cat in qwen_df.index else 0.0
        ft_f1 = ft_df.loc[cat, 'F1'] if cat in ft_df.index else 0.0
        if q_f1 > ft_f1 + 0.1:
            gaps.append(f"- {cat}: è½å {abs(ft_f1 - q_f1)*100:.1f}%")
    
    if not gaps:
        print("ğŸ‰ Local Finetuned æ¨¡å‹å·²åŸºæœ¬è¿½å¹³ Qwen3ï¼")
    else:
        print(f"åœ¨ä»¥ä¸‹ {len(gaps)} ä¸ªé¢†åŸŸä»æœ‰è¾ƒå¤§å·®è·:")
        for g in gaps:
            print(g)

def main():
    print("Start analyzing...", flush=True)
    doc_ids = list_document_ids()
    if not doc_ids:
        print("No ground truth found.")
        return
        
    print(f"Analyzing {len(doc_ids)} documents: {doc_ids}", flush=True)
    
    all_results = []
    # ç­›é€‰è¦å¯¹æ¯”çš„æ–¹æ³•
    methods_to_run = [m for m in METHODS.keys() if m != 'ground truth']
    
    for method in methods_to_run:
        print(f"Processing {method}...", flush=True)
        df = analyze_method_detailed(method, doc_ids)
        all_results.append(df)
    
    final_df = pd.concat(all_results, ignore_index=True)
    
    # 1. ä¿å­˜è¯¦ç»† CSV
    out_csv = os.path.join(os.path.dirname(__file__), "result", "detailed_metrics_by_category.csv")
    final_df.sort_values(by=['Category', 'F1'], ascending=[True, False]).to_csv(out_csv, index=False, float_format='%.4f')
    print(f"\nDetailed metrics saved to: {out_csv}")
    
    # 2. æ‰“å°å¯¹æ¯”è¡¨æ ¼ï¼ˆPivot Tableï¼‰
    pivot = final_df.pivot(index='Category', columns='Method', values='F1')
    print("\n" + "="*60)
    print("F1 Score Comparison Matrix")
    print("="*60)
    print(pivot.round(4))
    
    # 3. è‡ªåŠ¨è¯Šæ–­ (ä¸‰æ–¹å¯¹æ¯”)
    generate_diagnosis_report(final_df)

if __name__ == "__main__":
    main()
