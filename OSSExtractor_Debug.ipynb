{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0361ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWEN_API_KEY set: True\n",
      "GOOGLE_API_KEY set: False\n"
     ]
    }
   ],
   "source": [
    "# 1) ç¯å¢ƒä¸å¼•æ“\n",
    "import os\n",
    "print('QWEN_API_KEY set:', bool(os.getenv('QWEN_API_KEY')))\n",
    "print('GOOGLE_API_KEY set:', bool(os.getenv('GOOGLE_API_KEY')))\n",
    "# é»˜è®¤æœ¬åœ°æ¨¡å¼ï¼Œå¯é€šè¿‡ NB_ENGINE è¦†ç›–ä¸º qwen/gemini\n",
    "if not os.getenv('NB_ENGINE'):\n",
    "    os.environ['NB_ENGINE'] = 'local'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dcbcd6",
   "metadata": {},
   "source": [
    "### ğŸ”¬ FlowDevExtractor æµåŠ¨åŒ–å­¦æå–å·¥å…· - è°ƒè¯•ç‰ˆæœ¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4e064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaowenyuan/miniconda3/envs/ossextractor/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å—å¯¼å…¥æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "## ğŸ“¦ å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 2) å¯¼å…¥\n",
    "from core.text_utils import extract_text_from_pdf, write_text\n",
    "from core.embedding import run_embedding_selection\n",
    "from core.models.qwen_llm import QwenLLM\n",
    "from core.models.gemini_llm import GeminiLLM\n",
    "from core.processor import UnifiedTextProcessor\n",
    "\n",
    "print(\"âœ… æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3ae59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['FCPD_TOP_N'] = '15' # å€™é€‰æ®µæ•° å¾®è°ƒä¸º20ï¼Œæœªå¾®è°ƒä¸º15\n",
    "os.environ['FCPD_EMB_KEEP_ORDER'] = '1' #ç¡®ä¿â€œè½»æ‹¼æ¥åçš„å†™å‡ºé¡ºåºä¹Ÿå¯æŒ‰åŸæ–‡é¡ºåºè¾“å‡ºâ€\n",
    "# åµŒå…¥é˜¶æ®µå¯¹çŸ­æ®µè½åšâ€œè½»æ‹¼æ¥â€ï¼Œæé«˜ä¿¡æ¯é‡ã€‚\n",
    "os.environ['FCPD_EMB_EXPAND'] = '1'      # 1å¼€å¯åˆå¹¶ï¼ˆé»˜è®¤å…³ï¼‰\n",
    "os.environ['FCPD_EMB_MIN_CHARS'] = '300' # å°äºæ­¤é•¿åº¦ä¼šå°è¯•åˆå¹¶\n",
    "os.environ['FCPD_EMB_MAX_CHARS'] = '1000'# åˆå¹¶åä¸Šé™ï¼Œé¿å…è¶…é•¿\n",
    "# åœ¨æ®µè½æŠ½å–å‰â€œé‡æ‹¼æ¥â€ç›¸é‚»æ®µï¼Œå……åˆ†åˆ©ç”¨4096ä¸Šä¸‹æ–‡ã€‚\n",
    "# os.environ['FCPD_SUM_PACK'] = '0'  # æœªå¾®è°ƒæ¨¡å¼\n",
    "os.environ['FCPD_SUM_PACK'] = '1'  # 0æ˜¯å…³é—­åˆå¹¶ å¾®è°ƒæ¨¡å¼\n",
    "os.environ['FCPD_SUM_PACK_MIN_CHARS'] = '500'\n",
    "os.environ['FCPD_SUM_PACK_MAX_CHARS'] = '1500'    \n",
    "# å¢å¼ºæ ‡é¢˜æ£€æµ‹çª—å£\n",
    "os.environ['FCPD_FILTER_TITLE_WINDOW'] = '100'\n",
    "# å…³é—­æ¨ç†\n",
    "os.environ['FCPD_RUN_IMPACT'] = '0' \n",
    "os.environ['FCPD_IMPACT_SOURCE'] = 'abstract' #ä» Abstract æå– Impactâ€\n",
    "\n",
    "os.environ['FCPD_OVERALL_MAX_CAND'] = '20'\n",
    "os.environ['FCPD_OVERALL_CHAR_BUDGET'] = '7000'\n",
    "os.environ['FCPD_OVERALL_CHUNK_SIZE'] = '10'\n",
    "# os.environ['FCPD_OVERALL_MAX_TOKENS'] = '1024' # Overall é˜¶æ®µå¯ä»¥é€‚å½“é™ä½è¾“å‡ºä¸Šé™ï¼ˆå› ä¸ºæœªå¾®è°ƒæ¨¡å‹é€šå¸¸è¾“å‡ºè¾ƒçŸ­ï¼‰\n",
    "os.environ['FCPD_OVERALL_MAX_TOKENS'] = '4096' #å¾®è°ƒæ¨¡å¼\n",
    "\n",
    "# å¼ºåˆ¶æ¿€æ´»å¾®è°ƒæ¨¡å¼é€»è¾‘\n",
    "os.environ['FCPD_FORCE_FINETUNED'] = '1'\n",
    "# å¼€å¯è°ƒè¯•æ—¥å¿—ä»¥ç¡®è®¤\n",
    "os.environ['FCPD_DEBUG'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195375cc",
   "metadata": {},
   "source": [
    "### ç®€è¦æµç¨‹\n",
    "- æœ¬åœ° LLMï¼ˆé»˜è®¤ï¼‰ï¼šäº”æ­¥æ³•ï¼ˆPDFâ†’TXT â†’ Embedding â†’ Filter â†’ Abstract â†’ Summarize/Overall/Impactï¼‰\n",
    "- åœ¨çº¿ LLMï¼ˆQwen/Geminiï¼‰ï¼šç›´è¾¾æ¨¡å¼ï¼ˆPDFâ†’TXT â†’ Fast Overall/Impactï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ å°†å¤„ç† 10 ä¸ªPDFæ–‡ä»¶:\n",
      "ğŸ“ ä¸»è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: evaluation/result/local llm finetuned\n",
      "----------------------------------------\n",
      "  1. æ­£åœ¨å¤„ç†: 0.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/0\n",
      "  2. æ­£åœ¨å¤„ç†: 1.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/1\n",
      "  3. æ­£åœ¨å¤„ç†: 2.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/2\n",
      "  4. æ­£åœ¨å¤„ç†: 3.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/3\n",
      "  5. æ­£åœ¨å¤„ç†: 5.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/5\n",
      "  6. æ­£åœ¨å¤„ç†: 6.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/6\n",
      "  7. æ­£åœ¨å¤„ç†: 7.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/7\n",
      "  8. æ­£åœ¨å¤„ç†: 8.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/8\n",
      "  9. æ­£åœ¨å¤„ç†: 9.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/9\n",
      "  10. æ­£åœ¨å¤„ç†: 10.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: evaluation/result/local llm finetuned/10\n"
     ]
    }
   ],
   "source": [
    "### ğŸ”§ é…ç½®å‚æ•°\n",
    "import os\n",
    "\n",
    "# é…ç½®è¦å¤„ç†çš„PDFæ–‡ä»¶\n",
    "pdf_files = [\n",
    "    # 'evaluation/raw papers/0.pdf',\n",
    "    'evaluation/raw papers/1.pdf',\n",
    "    'evaluation/raw papers/2.pdf',\n",
    "    'evaluation/raw papers/3.pdf',\n",
    "    'evaluation/raw papers/4.pdf',\n",
    "    'evaluation/raw papers/5.pdf',\n",
    "    'evaluation/raw papers/6.pdf',\n",
    "    'evaluation/raw papers/7.pdf',\n",
    "    'evaluation/raw papers/8.pdf',\n",
    "    'evaluation/raw papers/9.pdf',\n",
    "    'evaluation/raw papers/10.pdf',\n",
    "    # å¦‚æœæœ‰æ›´å¤šæ–‡ä»¶ï¼Œå¯ä»¥åŠ åœ¨è¿™é‡Œ\n",
    "]\n",
    "\n",
    "# å®šä¹‰åŸºç¡€çš„æ•°æ®ç›®å½•\n",
    "base_data_dir = 'evaluation/result'\n",
    "\n",
    "# 1. åœ¨Dataç›®å½•ä¸‹ï¼Œå®šä¹‰ä¸€ä¸ªåä¸º 'output' çš„ä¸»è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„\n",
    "main_output_dir = os.path.join(base_data_dir, 'local llm finetuned')\n",
    "# main_output_dir = os.path.join(base_data_dir, 'local llm unfinetuned')\n",
    "\n",
    "# 2. åˆ›å»º 'output' æ–‡ä»¶å¤¹ (å¦‚æœå®ƒä¸å­˜åœ¨çš„è¯)\n",
    "# exist_ok=True è¡¨ç¤ºå¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ¥é”™\n",
    "os.makedirs(main_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“„ å°†å¤„ç† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶:\")\n",
    "print(f\"ğŸ“ ä¸»è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: {main_output_dir}\")\n",
    "print(\"-\" * 40) # æ‰“å°åˆ†å‰²çº¿\n",
    "\n",
    "# éå†æ¯ä¸€ä¸ªè¦å¤„ç†çš„PDFæ–‡ä»¶\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    \n",
    "    # 3. ä»å®Œæ•´è·¯å¾„ä¸­è·å–PDFçš„æ–‡ä»¶å (ä¾‹å¦‚: 'd2cp03073j.pdf')\n",
    "    pdf_filename = os.path.basename(pdf_path)\n",
    "    \n",
    "    # 4. å»æ‰.pdfæ‰©å±•åï¼Œåˆ›å»ºæ–‡ä»¶å¤¹å (ä¾‹å¦‚: 'd2cp03073j')\n",
    "    folder_name = os.path.splitext(pdf_filename)[0]\n",
    "    \n",
    "    # 5. æ‹¼æ¥å‡ºè¿™ä¸ªPDFä¸“å±çš„è¾“å‡ºæ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„\n",
    "    specific_output_dir = os.path.join(main_output_dir, folder_name)\n",
    "    \n",
    "    # 6. åˆ›å»ºè¿™ä¸ªä¸“å±çš„æ–‡ä»¶å¤¹\n",
    "    os.makedirs(specific_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"  {i}. æ­£åœ¨å¤„ç†: {pdf_filename}\")\n",
    "    print(f\"     -> å°†è¾“å‡ºåˆ°: {specific_output_dir}\")\n",
    "    # --- åœ¨è¿™é‡Œæ¥ä¸Šä½ åç»­çš„å¤„ç†é€»è¾‘ ---\n",
    "    # ä¾‹å¦‚ï¼Œä½ ä¹‹åæ‰€æœ‰ä¿å­˜æ–‡ä»¶çš„æ“ä½œï¼Œéƒ½åº”è¯¥ä½¿ç”¨ `specific_output_dir` ä½œä¸ºè·¯å¾„\n",
    "    # processed_text_path = os.path.join(specific_output_dir, 'Processed_text.txt')\n",
    "    # with open(processed_text_path, 'w') as f:\n",
    "    #     f.write(\"è¿™é‡Œæ˜¯å¤„ç†åçš„æ–‡æœ¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5b45d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ä½ å¯ä»¥åœ¨è¿™é‡Œä¸ºä¸åŒçš„å¤„ç†é˜¶æ®µæŒ‡å®šä½¿ç”¨ä¸åŒçš„LLMæ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144fc9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Debug] LocalPipeline Init: Summarize='My_Finetuned_Model_Q4_K_M_Mixed.gguf', Overall='My_Finetuned_Model_Q4_K_M_Mixed.gguf'\n",
      "  [Debug] Finetuned Trigger: 'My_Finetuned_Model'\n",
      "============================================================\n",
      "ğŸ›ï¸  å¼•æ“é…ç½®\n",
      "============================================================\n",
      "ğŸ“Œ å¼•æ“:          local\n",
      "ğŸ“Œ å½’æ¡£ç›®å½•å:     local llm\n",
      "ğŸ“Œ æœ¬åœ°å­è·¯å¾„:     local+finetune\n",
      "============================================================\n",
      "âœ… å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ˆä¸ä¼šé‡å¤å®ä¾‹åŒ–ï¼‰\n"
     ]
    }
   ],
   "source": [
    "### æ¨¡å‹é…ç½® - åˆ†é˜¶æ®µè‡ªå®šä¹‰\n",
    "\"\"\"\n",
    "ğŸ›ï¸ å¼•æ“åˆå§‹åŒ–ï¼ˆå•æ¬¡ï¼‰\n",
    "æ”¯æŒå¼•æ“: local | qwen | gemini\n",
    "ä¼˜å…ˆè¯»å– config.yamlï¼›è‹¥ NB_ENGINE è®¾ç½®ä¸”åˆæ³•åˆ™è¦†ç›–ã€‚\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "\n",
    "# è¯»å–é…ç½®\n",
    "with open('config.yaml', 'r', encoding='utf-8') as f:\n",
    "    _cfg = yaml.safe_load(f) or {}\n",
    "\n",
    "_engine_cfg = (_cfg.get('engine', 'local') or 'local').strip().lower()\n",
    "_engine_env = (os.getenv('NB_ENGINE') or '').strip().lower()\n",
    "ENGINE = _engine_env if _engine_env in ['local','qwen','gemini'] else _engine_cfg\n",
    "\n",
    "# é»˜è®¤é™åˆ¶åµŒå…¥TOP_Nï¼Œé¿å…å†…å­˜/æ˜¾å­˜å‹åŠ›\n",
    "if not os.getenv('FCPD_TOP_N'):\n",
    "    os.environ['FCPD_TOP_N'] = '10'\n",
    "\n",
    "# åˆå§‹åŒ–å¤„ç†å™¨å®ä¾‹ï¼ˆå•æ¬¡ï¼‰\n",
    "if ENGINE == 'local':\n",
    "    from core.local_pipeline import LocalPipeline\n",
    "    lc = _cfg.get('local_model', {})\n",
    "    engine = LocalPipeline(\n",
    "        model_name=None,\n",
    "        model_path=lc.get('path', 'models/'),\n",
    "        filter_model=lc.get('filter'),\n",
    "        abstract_model=lc.get('abstract'),\n",
    "        summarize_model=lc.get('summarize'),\n",
    "        overall_model=lc.get('overall'),\n",
    "        impact_model=lc.get('impact'),\n",
    "        finetuned_trigger_name=lc.get('finetuned_trigger_name', 'My_Finetuned_Model'),\n",
    "    )\n",
    "    ENGINE_NAME = 'local llm'\n",
    "    # åˆ¤å®šæœ¬åœ°å­è·¯å¾„ï¼ˆæœªå¾®è°ƒ/å¾®è°ƒï¼‰\n",
    "    try:\n",
    "        _sn = getattr(engine, 'model_summarize_name', None) or ''\n",
    "        _on = getattr(engine, 'model_overall_name', None) or ''\n",
    "        _is_ft = (_sn and engine._is_finetuned_model(_sn)) or (_on and engine._is_finetuned_model(_on))\n",
    "        LOCAL_SUBPATH = 'local+finetune' if _is_ft else 'local (classic)'\n",
    "    except Exception:\n",
    "        LOCAL_SUBPATH = 'local (classic)'\n",
    "elif ENGINE == 'qwen':\n",
    "    q = _cfg.get('qwen_api', {})\n",
    "    llm = QwenLLM(api_key_env_var=q.get('api_key_env_var', 'QWEN_API_KEY'), \n",
    "                  model_name=q.get('model_name', 'qwen-plus'))\n",
    "    engine = UnifiedTextProcessor(llm)\n",
    "    ENGINE_NAME = 'qwen'\n",
    "    LOCAL_SUBPATH = None\n",
    "else:\n",
    "    # Gemini\n",
    "    g = _cfg.get('gemini_api', {})\n",
    "    llm = GeminiLLM(api_key_env_var=g.get('api_key_env_var', 'GOOGLE_API_KEY'), \n",
    "                    model_name=g.get('model_name', 'gemini-1.5-flash'))\n",
    "    engine = UnifiedTextProcessor(llm)\n",
    "    ENGINE_NAME = 'gemini'\n",
    "    LOCAL_SUBPATH = None\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ›ï¸  å¼•æ“é…ç½®\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“Œ å¼•æ“:          {ENGINE}\")\n",
    "print(f\"ğŸ“Œ å½’æ¡£ç›®å½•å:     {ENGINE_NAME}\")\n",
    "if ENGINE == 'local':\n",
    "    print(f\"ğŸ“Œ æœ¬åœ°å­è·¯å¾„:     {LOCAL_SUBPATH}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"âœ… å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ˆä¸ä¼šé‡å¤å®ä¾‹åŒ–ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eb3a6",
   "metadata": {},
   "source": [
    "## ğŸ“„ æ­¥éª¤ 1: PDFè½¬æ–‡æœ¬å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a110213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...\n",
      "==================================================\n",
      "âœ… PDFè½¬æ–‡æœ¬å®Œæˆå¹¶å·²å½’æ¡£ï¼ç”Ÿæˆäº† 10 ä¸ªæ–‡æœ¬æ–‡ä»¶:\n",
      "  1. evaluation/result/local llm finetuned/0/0.txt\n",
      "     ğŸ“Š è¡Œæ•°: 137\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 32888 bytes\n",
      "  2. evaluation/result/local llm finetuned/1/1.txt\n",
      "     ğŸ“Š è¡Œæ•°: 253\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 22013 bytes\n",
      "  3. evaluation/result/local llm finetuned/2/2.txt\n",
      "     ğŸ“Š è¡Œæ•°: 251\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 46012 bytes\n",
      "  4. evaluation/result/local llm finetuned/3/3.txt\n",
      "     ğŸ“Š è¡Œæ•°: 277\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 31911 bytes\n",
      "  5. evaluation/result/local llm finetuned/5/5.txt\n",
      "     ğŸ“Š è¡Œæ•°: 263\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 42726 bytes\n",
      "  6. evaluation/result/local llm finetuned/6/6.txt\n",
      "     ğŸ“Š è¡Œæ•°: 1169\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 37606 bytes\n",
      "  7. evaluation/result/local llm finetuned/7/7.txt\n",
      "     ğŸ“Š è¡Œæ•°: 159\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 18723 bytes\n",
      "  8. evaluation/result/local llm finetuned/8/8.txt\n",
      "     ğŸ“Š è¡Œæ•°: 83\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 21628 bytes\n",
      "  9. evaluation/result/local llm finetuned/9/9.txt\n",
      "     ğŸ“Š è¡Œæ•°: 1031\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 36427 bytes\n",
      "  10. evaluation/result/local llm finetuned/10/10.txt\n",
      "     ğŸ“Š è¡Œæ•°: 173\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 29261 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ç›´æ¥ä½¿ç”¨æ–°å·¥å…·å°†PDFè½¬ä¸ºtxt\n",
    "output_files = []\n",
    "for pdf in pdf_files:\n",
    "    base = os.path.splitext(os.path.basename(pdf))[0]\n",
    "    out_dir = os.path.join(main_output_dir, base)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_txt = os.path.join(out_dir, f\"{base}.txt\")\n",
    "    text = extract_text_from_pdf(pdf)\n",
    "    write_text(text, out_txt)\n",
    "    output_files.append(out_txt)\n",
    "\n",
    "# # å½’æ¡£åˆ°å¼•æ“ç›®å½•ï¼ˆä¸mainä¸€è‡´ï¼‰\n",
    "# engine_name = ENGINE_NAME  # ç”±å¼•æ“åˆå§‹åŒ–å•å…ƒç¡®å®š\n",
    "# for txt in output_files:\n",
    "#     base = os.path.splitext(os.path.basename(txt))[0]\n",
    "#     dest_dir = os.path.join(main_output_dir, '..', engine_name, base)\n",
    "#     os.makedirs(dest_dir, exist_ok=True)\n",
    "#     try:\n",
    "#         shutil.copy2(txt, os.path.join(dest_dir, os.path.basename(txt)))\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "print(f\"âœ… PDFè½¬æ–‡æœ¬å®Œæˆå¹¶å·²å½’æ¡£ï¼ç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶:\")\n",
    "for i, file in enumerate(output_files, 1):\n",
    "    print(f\"  {i}. {file}\")\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"     ğŸ“Š è¡Œæ•°: {len(lines)}\")\n",
    "            print(f\"     ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(file)} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d163864",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹PDFè½¬æ–‡æœ¬ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383ac1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†æŸ¥çœ‹\n",
    "# sample_file = output_files[0]\n",
    "# print(f\"ğŸ“– æŸ¥çœ‹æ–‡ä»¶: {os.path.basename(sample_file)}\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# with open(sample_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "#     content = f.read()\n",
    "    \n",
    "# print(f\"ğŸ“Š æ€»å­—ç¬¦æ•°: {len(content)}\")\n",
    "# print(f\"ğŸ“Š æ€»è¡Œæ•°: {len(content.splitlines())}\")\n",
    "# print(\"\\nğŸ“„ å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\")\n",
    "# print(\"-\" * 30)\n",
    "# print(content[:500] + \"...\" if len(content) > 500 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c6cf3",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤ 2: æ–‡æœ¬é¢„å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab72e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...\n",
      "==================================================\n",
      "âœ… é¢„å¤„ç†å®Œæˆï¼ˆç›´é€šï¼‰ã€‚æ–‡ä»¶æ•°: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ–°æ¶æ„ï¼šé¢„å¤„ç†æ•´åˆåˆ°åç»­æµç¨‹ï¼Œç›´æ¥ä½¿ç”¨åŸtxtå³å¯\n",
    "processed_files = list(output_files)\n",
    "print(f\"âœ… é¢„å¤„ç†å®Œæˆï¼ˆç›´é€šï¼‰ã€‚æ–‡ä»¶æ•°: {len(processed_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab9779",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹é¢„å¤„ç†ç»“æœ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664887d",
   "metadata": {},
   "source": [
    "### ğŸ’¡ LLMå†…å®¹è¿‡æ»¤è¯´æ˜\n",
    "\n",
    "**è¿™ä¸€æ­¥çš„ä½œç”¨ï¼š**\n",
    "- è¾“å…¥ï¼šåµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰å‡ºçš„æ®µè½ï¼ˆå¦‚20ä¸ªæ®µè½ï¼‰\n",
    "- å¤„ç†ï¼šä½¿ç”¨Nous-Hermes-Llama2-13Bæ¨¡å‹åˆ¤æ–­æ¯ä¸ªæ®µè½æ˜¯å¦çœŸæ­£ä¸è¡¨é¢åŒ–å­¦ååº”ç›¸å…³\n",
    "- è¾“å‡ºï¼šè¿›ä¸€æ­¥ç­›é€‰çš„ç›¸å…³æ®µè½ï¼ˆå¦‚10ä¸ªæ®µè½ï¼‰\n",
    "\n",
    "**æ¨¡å‹é€‰æ‹©ï¼š**\n",
    "- ä¼˜å…ˆä½¿ç”¨ï¼šNous-Hermes-Llama2-13B-Instructï¼ˆæ›´æ™ºèƒ½ï¼Œæ€§èƒ½æ›´å¥½ï¼‰\n",
    "- å›é€€æ¨¡å‹ï¼šnous-hermes-llama2-13bï¼ˆç¨³å®šå¯é ï¼‰\n",
    "\n",
    "**ä¸ºä»€ä¹ˆæ®µè½æ•°ä¼šå‡å°‘ï¼š**\n",
    "- åµŒå…¥ç›¸ä¼¼åº¦åªæ˜¯åŸºäºå…³é”®è¯åŒ¹é…\n",
    "- LLMè¿‡æ»¤ä¼šè¿›è¡Œæ›´æ™ºèƒ½çš„å†…å®¹ç†è§£\n",
    "- æœ€ç»ˆä¿ç•™çœŸæ­£ç›¸å…³çš„æ®µè½\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b4595",
   "metadata": {},
   "source": [
    "## ğŸ” æ­¥éª¤ 3: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d9b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/10: 0.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/0/Embedding_0.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 2/10: 1.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/1/Embedding_1.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 3/10: 2.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/2/Embedding_2.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 4/10: 3.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/3/Embedding_3.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 5/10: 5.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/5/Embedding_5.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 6/10: 6.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/6/Embedding_6.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 7/10: 7.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/7/Embedding_7.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 8/10: 8.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/8/Embedding_8.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 9/10: 9.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/9/Embedding_9.txt\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 10/10: 10.txt\n",
      "  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: evaluation/result/local llm finetuned/10/Embedding_10.txt\n",
      "\n",
      "ğŸ‰ åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from core.embedding import run_embedding_selection\n",
    "\n",
    "embedding_files = []\n",
    "for i, processed_file in enumerate(processed_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(processed_files)}: {os.path.basename(processed_file)}\")\n",
    "    emb = run_embedding_selection(processed_file, top_n=int(os.getenv('FCPD_TOP_N','10')))\n",
    "    embedding_files.append(emb)\n",
    "    print(f\"  âœ… ç”ŸæˆåµŒå…¥ç­›é€‰æ–‡ä»¶: {emb}\")\n",
    "\n",
    "# # å½’æ¡£\n",
    "# try:\n",
    "#     engine_name = ENGINE_NAME\n",
    "#     for emb in embedding_files:\n",
    "#         base = os.path.splitext(os.path.basename(emb))[0].replace('Embedding_','')\n",
    "#         dest_dir = os.path.join(main_output_dir, '..', engine_name, base)\n",
    "#         os.makedirs(dest_dir, exist_ok=True)\n",
    "#         if os.path.exists(emb):\n",
    "#             shutil.copy2(emb, os.path.join(dest_dir, os.path.basename(emb)))\n",
    "# except Exception:\n",
    "#     pass\n",
    "\n",
    "print(f\"\\nğŸ‰ åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572a33b",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹åµŒå…¥ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0bc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: Embedding_0.txt\n",
      "==================================================\n",
      "ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: 30\n",
      "\n",
      "ğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1: ABSTRACT: In this work, continuous flow nitration of trifluoromethoxybenzene (TFMB) was conducted in a microchannel reactor. The eï¬€ects of process parameters, including temperature, residence time, su...\n",
      "æ®µè½ 3: of the workup. Apart from those substantial advantages presented above, with the numbering-up strategy, the small scaling eï¬€ect of microreactor makes the laboratory results easier to industrialize.9 G...\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹åµŒå…¥ç»“æœ\n",
    "sample_embedding = embedding_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: {os.path.basename(sample_embedding)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_embedding, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: {len(lines)}\")\n",
    "print(\"\\nğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"æ®µè½ {i+1}: {line[:200]}...\" if len(line) > 200 else f\"æ®µè½ {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860a8f4",
   "metadata": {},
   "source": [
    "## ğŸ¤– æ­¥éª¤ 4: LLMå†…å®¹è¿‡æ»¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af29236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 4-5/5: æ¨ç†ä¸å½’æ¡£ (æœ¬åœ°=äº”æ­¥æ³• / åœ¨çº¿=ç›´è¾¾)...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/10: Embedding_0.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 12, è§£ææˆåŠŸ: 11, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 2/10: Embedding_1.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 7, è§£ææˆåŠŸ: 7, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 3/10: Embedding_2.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 9, è§£ææˆåŠŸ: 9, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 4/10: Embedding_3.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 8, è§£ææˆåŠŸ: 8, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 5/10: Embedding_5.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 8, è§£ææˆåŠŸ: 8, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 6/10: Embedding_6.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 2, è§£ææˆåŠŸ: 2, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 7/10: Embedding_7.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 3, è§£ææˆåŠŸ: 3, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 8/10: Embedding_8.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 4, è§£ææˆåŠŸ: 4, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 9/10: Embedding_9.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 2, è§£ææˆåŠŸ: 2, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 10/10: Embedding_10.txt\n",
      "  â© è·³è¿‡ Abstract æ­¥éª¤ (ä¼˜åŒ–)\n",
      "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 7, è§£ææˆåŠŸ: 7, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[1]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"nitration\"}, \"reactants\": [{\"name\": \"TFMB\", \"role\": \"reactant\"}], \"products\": [{\"name\": \"p-NB\", \"yield_optimal\": null, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": null, \"inner_diameter\": nu...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[2]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"photoreduction\"}, \"reactants\": [{\"name\": \"nitrobenzene\", \"role\": \"substrate\"}], \"products\": [{\"name\": \"PHA\", \"yield_optimal\": 96, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": \"coil\", \"inner_...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[3]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"alkylation\"}, \"reactants\": [{\"name\": \"imidazolium salt\", \"role\": \"catalyst\"}], \"products\": [{\"name\": \"butylpyridinium bromide\", \"yield_optimal\": 15.03, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[4]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"hydrogenation\"}, \"reactants\": [{\"name\": \"3-methyl-2-nitrobenzoic acid\", \"role\": \"reactant\"}], \"products\": [], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": \"coil\", \"inner_diameter\": \"0.5 mm\"}, \"metrics\": {\"...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[5]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"hydrogenation\"}, \"reactants\": [{\"name\": \"3-methyl-2-nitrobenzoic acid\", \"role\": \"reactant\"}], \"products\": [{\"name\": null, \"yield_optimal\": 82.9, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": \"240 min\"}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"ty...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[6]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"hydrogenation\"}, \"reactants\": [{\"name\": \"MNA\", \"role\": \"reactant\"}], \"products\": [{\"name\": \"AMA\", \"yield_optimal\": 99, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": \"coil\", \"inner_diameter\": ...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[7]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"photoreduction\"}, \"reactants\": [{\"name\": \"DHAA\", \"role\": \"reactant\"}], \"products\": [], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": \"coil\", \"inner_diameter\": \"0.5 mm\"}, \"metrics\": {\"conversion\": 100, \"yiel...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[8]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"halogenation\"}, \"reactants\": [{\"name\": \"aceto-phenone\", \"role\": \"reactant\"}], \"products\": [{\"name\": null, \"yield_optimal\": 99.0, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": \"60 s\"}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": \"microreactors...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[9]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"halogenation\"}, \"reactants\": [{\"name\": \"p-DVB\", \"role\": \"reactant\"}], \"products\": [{\"name\": \"p-DEB\", \"yield_optimal\": 99.2, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": \"20â€“40 mL/min\"}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": null, \"inne...\n",
      "\n",
      "ğŸ§© Overall é¢„è§ˆ[10]:\n",
      " {\"reaction_summary\": {\"reaction_type\": \"oxidation\"}, \"reactants\": [{\"name\": \"crotonaldehyde\", \"role\": \"reactant\"}], \"products\": [{\"name\": \"crotonic acid\", \"yield_optimal\": 95.6, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": null}, {\"type\": \"residence_time\", \"value\": \"3 min\"}, {\"type\": \"flow_rate_total\", \"value\": null}, {\"type\": \"pressure\", \"value\": \"4 MPa\"}], \"reactor\": {\"type\": \"...\n",
      "\n",
      "ğŸ‰ æ¨ç†å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 4-5/5: æ¨ç†ä¸å½’æ¡£ (æœ¬åœ°=äº”æ­¥æ³• / åœ¨çº¿=ç›´è¾¾)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_outputs = {\n",
    "    'filter': [],\n",
    "    'summarized': [],\n",
    "    'summarized_overall': [],\n",
    "    'impact_analysis': [],\n",
    "}\n",
    "\n",
    "for i, embedding_file in enumerate(embedding_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(embedding_files)}: {os.path.basename(embedding_file)}\")\n",
    "\n",
    "    if ENGINE == 'local':\n",
    "        # æœ¬åœ°ï¼šäº”æ­¥æ³•ï¼ŒåŸºäº Embedding æ–‡ä»¶\n",
    "        res = engine.process_text_file_comprehensive(embedding_file, mode='comprehensive')\n",
    "    else:\n",
    "        # åœ¨çº¿ï¼šç›´è¾¾æ¨¡å¼ï¼ˆfastï¼‰ï¼Œç›´æ¥ç”¨åŸå§‹TXT\n",
    "        original_txt_file = output_files[i-1]\n",
    "        res = engine.process_text_file_comprehensive(original_txt_file, mode='fast')\n",
    "\n",
    "    # æ”¶é›†\n",
    "    final_outputs['filter'].append(res.get('filter'))\n",
    "    final_outputs['summarized'].append(res.get('summarized'))\n",
    "    final_outputs['summarized_overall'].append(res.get('summarized_overall'))\n",
    "    final_outputs['impact_analysis'].append(res.get('impact_analysis'))\n",
    "\n",
    "    # å½’æ¡£\n",
    "    try:\n",
    "        if ENGINE == 'local':\n",
    "            base = os.path.splitext(os.path.basename(embedding_file))[0].replace('Embedding_','')\n",
    "        else:\n",
    "            base = os.path.splitext(os.path.basename(original_txt_file))[0]\n",
    "        dest_dir = os.path.join(main_output_dir, '..', ENGINE_NAME, base)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        for p in res.values():\n",
    "            if p and os.path.exists(p):\n",
    "                shutil.copy2(p, os.path.join(dest_dir, os.path.basename(p)))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ç®€è¦é¢„è§ˆï¼šOverall / Impact\n",
    "for i, (overall, impact) in enumerate(zip(final_outputs['summarized_overall'], final_outputs['impact_analysis']), 1):\n",
    "    if overall and os.path.exists(overall):\n",
    "        with open(overall, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            s = f.read()\n",
    "        print(f\"\\nğŸ§© Overall é¢„è§ˆ[{i}]:\\n\", (s[:400] + '...') if len(s) > 400 else s)\n",
    "    if impact and os.path.exists(impact):\n",
    "        with open(impact, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            s = f.read()\n",
    "        print(f\"\\nğŸ“Š Impact é¢„è§ˆ[{i}]:\\n\", (s[:400] + '...') if len(s) > 400 else s)\n",
    "\n",
    "print(\"\\nğŸ‰ æ¨ç†å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bac3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # å…œåº•ï¼šè‹¥æœªåˆå§‹åŒ– engineï¼Œåˆ™å¿«é€Ÿåˆå§‹åŒ–ä¸€æ¬¡\n",
    "# if 'engine' not in globals():\n",
    "#     import os, yaml\n",
    "#     from core.local_pipeline import LocalPipeline\n",
    "#     from core.models.qwen_llm import QwenLLM\n",
    "#     from core.models.gemini_llm import GeminiLLM\n",
    "#     from core.processor import UnifiedTextProcessor\n",
    "\n",
    "#     cfg = yaml.safe_load(open('config.yaml','r',encoding='utf-8')) or {}\n",
    "#     eng = (os.getenv('NB_ENGINE') or cfg.get('engine','local')).strip().lower()\n",
    "#     if eng == 'local':\n",
    "#         lc = cfg.get('local_model',{}) or {}\n",
    "#         engine = LocalPipeline(\n",
    "#             model_name=None,\n",
    "#             model_path=lc.get('path','models/'),\n",
    "#             filter_model=lc.get('filter'),\n",
    "#             abstract_model=lc.get('abstract'),\n",
    "#             summarize_model=lc.get('summarize'),\n",
    "#             overall_model=lc.get('overall'),\n",
    "#             impact_model=lc.get('impact'),\n",
    "#             finetuned_trigger_name=lc.get('finetuned_trigger_name','My_Finetuned_Model'),\n",
    "#         )\n",
    "#     elif eng == 'qwen':\n",
    "#         q = cfg.get('qwen_api',{}) or {}\n",
    "#         llm = QwenLLM(api_key_env_var=q.get('api_key_env_var','QWEN_API_KEY'), model_name=q.get('model_name','qwen-plus'))\n",
    "#         engine = UnifiedTextProcessor(llm)\n",
    "#     else:\n",
    "#         g = cfg.get('gemini_api',{}) or {}\n",
    "#         llm = GeminiLLM(api_key_env_var=g.get('api_key_env_var','GOOGLE_API_KEY'), model_name=g.get('model_name','gemini-1.5-flash'))\n",
    "#         engine = UnifiedTextProcessor(llm)\n",
    "\n",
    "# import os, pandas as pd\n",
    "\n",
    "# # 1) æŒ‡å®šä½ çš„ Summarized æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ª JSONï¼‰\n",
    "# summarized_file = 'evaluation/result/local llm finetuned/1/Embedding_1_Summarized.txt'\n",
    "\n",
    "# # 2) è¯»å–ä¸º DataFrame çš„ summarized åˆ—\n",
    "# with open(summarized_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "#     lines = [ln.strip() for ln in f if ln.strip()]\n",
    "# df_summarized = pd.DataFrame(lines, columns=['summarized'])\n",
    "\n",
    "# # 3) è°ƒç”¨åˆå¹¶ï¼Œä»…æ‰§è¡Œ Overallï¼ˆä¼šä½¿ç”¨ä¼˜åŒ–åçš„å¾®è°ƒåˆå¹¶æç¤ºè¯ï¼‰\n",
    "# overall_json = engine.summarize_document_overall(df_summarized)\n",
    "\n",
    "# # 4) ä¿å­˜\n",
    "# overall_file = summarized_file.replace('_Summarized.txt', '_Overall.txt')\n",
    "# with open(overall_file, 'w', encoding='utf-8') as f:\n",
    "#     f.write(overall_json)\n",
    "\n",
    "# print('âœ… Overall å†™å…¥:', overall_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23832a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ossextractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
