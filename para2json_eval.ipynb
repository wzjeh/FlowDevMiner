{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# para2json å¾®è°ƒæ¨¡å‹æœ¬åœ°è¯„æµ‹\n",
        "\n",
        "æœ¬ Notebook ç”¨äºå¿«é€Ÿæµ‹è¯•å¾®è°ƒåçš„ para2jsonï¼ˆæ®µè½â†’JSONï¼‰æ¨¡å‹åœ¨æœ¬ä»“åº“ç®¡çº¿ä¸­çš„æ•ˆæœï¼ˆä¸é¢å¤–ç”Ÿæˆæ–‡æ¡£ï¼Œä»…ä»£ç ä¸ç»“æœå±•ç¤ºï¼‰ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os; os.environ[\"FCPD_POST_STRICT\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å¯¹æ¯”æ¨¡å‹:\n",
            "- å¾®è°ƒ: My_Finetuned_Model_Q4_K_M_Mixed.gguf\n",
            "- åŸå§‹: meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\n"
          ]
        }
      ],
      "source": [
        "import os, yaml, pathlib\n",
        "\n",
        "# é¡¹ç›®æ ¹è·¯å¾„\n",
        "ROOT = pathlib.Path('/Users/zhaowenyuan/Projects/FCPDExtractor')\n",
        "CFG_PATH = ROOT / 'config.yaml'\n",
        "MODELS_DIR = ROOT / 'models'\n",
        "\n",
        "# è¯»å–é…ç½®ï¼ˆä»…ç”¨äºå– finetuned_trigger_nameï¼‰\n",
        "with open(CFG_PATH, 'r', encoding='utf-8') as f:\n",
        "    cfg = yaml.safe_load(f) or {}\n",
        "local_cfg = (cfg.get('local_model') or {})\n",
        "\n",
        "# å›ºå®šå¯¹æ¯”çš„ä¸¤ä¸ªæ¨¡å‹ï¼ˆä¸åšåŠ¨æ€æ¢æµ‹ï¼‰\n",
        "FT_NAME = 'My_Finetuned_Model_Q4_K_M_Mixed.gguf'\n",
        "BASE_NAME = 'meta-llama-3.1-8b-instruct-q4_k_m-2.gguf'\n",
        "\n",
        "assert (MODELS_DIR / FT_NAME).exists(), f'æœªæ‰¾åˆ°å¾®è°ƒæ¨¡å‹: {FT_NAME}'\n",
        "assert (MODELS_DIR / BASE_NAME).exists(), f'æœªæ‰¾åˆ°åŸå§‹æ¨¡å‹: {BASE_NAME}'\n",
        "\n",
        "print('å¯¹æ¯”æ¨¡å‹:')\n",
        "print('- å¾®è°ƒ:', FT_NAME)\n",
        "print('- åŸå§‹:', BASE_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å¾®è°ƒæ¨¡å‹(æ‰‹åŠ¨å¯¹æ¯”): My_Finetuned_Model_Q4_K_M_Mixed.gguf\n",
            "åŸå§‹æ¨¡å‹(æ‰‹åŠ¨å¯¹æ¯”): meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\n"
          ]
        }
      ],
      "source": [
        "from core.local_pipeline import LocalPipeline\n",
        "\n",
        "# å…³é—­ Llama3.1 chat æ¨¡æ¿ï¼Œå¼ºåˆ¶ä½¿ç”¨æ™®é€š promptï¼ˆä¸ gpt4all/gguf æœ€ç¨³ï¼‰\n",
        "USE_PLAIN_PROMPT = True\n",
        "\n",
        "class ManualPipeline(LocalPipeline):\n",
        "    def _get_chat_prompt(self, system: str, user: str, context: str = \"\", stage: str = \"filter\") -> str:\n",
        "        if USE_PLAIN_PROMPT:\n",
        "            return self._create_prompt(system, user, context)\n",
        "        return super()._get_chat_prompt(system, user, context, stage)\n",
        "\n",
        "# ä½¿ç”¨ä¸Šä¸€å•å…ƒä¸­å›ºå®šçš„æ¨¡å‹åç§°\n",
        "assert (MODELS_DIR / FT_NAME).exists(), f'æœªæ‰¾åˆ°å¾®è°ƒæ¨¡å‹: {FT_NAME}'\n",
        "assert (MODELS_DIR / BASE_NAME).exists(), f'æœªæ‰¾åˆ°åŸå§‹æ¨¡å‹: {BASE_NAME}'\n",
        "\n",
        "pipeline_ft_manual = ManualPipeline(\n",
        "    model_name=None,\n",
        "    model_path=str(MODELS_DIR),\n",
        "    summarize_model=FT_NAME,\n",
        "    finetuned_trigger_name=local_cfg.get('finetuned_trigger_name', 'My_Finetuned_Model'),\n",
        ")\n",
        "\n",
        "pipeline_base_manual = ManualPipeline(\n",
        "    model_name=None,\n",
        "    model_path=str(MODELS_DIR),\n",
        "    summarize_model=BASE_NAME,\n",
        "    finetuned_trigger_name=local_cfg.get('finetuned_trigger_name', 'My_Finetuned_Model'),\n",
        ")\n",
        "\n",
        "print('å¾®è°ƒæ¨¡å‹(æ‰‹åŠ¨å¯¹æ¯”):', FT_NAME)\n",
        "print('åŸå§‹æ¨¡å‹(æ‰‹åŠ¨å¯¹æ¯”):', BASE_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ‰‹åŠ¨è¾“å…¥æ®µè½å¯¹æ¯”ï¼ˆä»… summarizeï¼‰\n",
        "\n",
        "è¯·åœ¨ä¸‹ä¸€ä¸ªå•å…ƒç¼–è¾‘ `PARAS` åˆ—è¡¨ï¼Œç„¶åè¿è¡Œâ€œè¿è¡Œä¸¤ä¸ªæ¨¡å‹ï¼Œç»Ÿè®¡è§£æç‡å¹¶é€æ®µå¯¹æ¯”â€å•å…ƒã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ®µè½æ•°: 1\n"
          ]
        }
      ],
      "source": [
        "# æ‰‹åŠ¨è¾“å…¥æ®µè½ï¼šç¼–è¾‘æ­¤åˆ—è¡¨\n",
        "PARAS = [\n",
        "    # ç¤ºä¾‹ï¼šè¯·ç”¨ä½ è‡ªå·±çš„æ®µè½æ›¿æ¢/è¿½åŠ \n",
        "    \"\"\"\n",
        "    Flow rate 0.1 mL/min, T=80 Â°C in a 0.5 mm coil; yield 82%.\n",
        "    \"\"\",\n",
        "]\n",
        "\n",
        "print(f\"æ®µè½æ•°: {len(PARAS)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä»…è¿è¡Œ summarizeï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼‰ï¼Œè¿”å›åŸå§‹ä¸è§£æåçš„JSON\n",
        "import json as _json\n",
        "import pandas as _pd\n",
        "\n",
        "_def_skeleton = {\n",
        "    \"reaction_summary\": {\n",
        "        \"reaction_type\": None,\n",
        "        \"reactants\": [],\n",
        "        \"products\": [],\n",
        "        \"conditions\": [],\n",
        "        \"reactor\": {\"type\": None, \"inner_diameter\": None},\n",
        "        \"metrics\": {\"conversion\": None, \"yield\": None, \"selectivity\": None, \"unit\": \"%\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "def run_summarize_in_memory(pipeline, paragraphs):\n",
        "    df = _pd.DataFrame({\"content\": [str(p) for p in paragraphs]})\n",
        "    out = pipeline.summarize_parameters(df)\n",
        "    raws = [str(s) for s in out.get('summarized', [])]\n",
        "    parsed = []\n",
        "    for s in raws:\n",
        "        t = s.strip().replace('```json','').replace('```','')\n",
        "        l, r = t.find('{'), t.rfind('}')\n",
        "        if l != -1 and r != -1 and r > l:\n",
        "            t = t[l:r+1]\n",
        "        try:\n",
        "            obj = _json.loads(t)\n",
        "            parsed.append(obj)\n",
        "        except Exception:\n",
        "            parsed.append(_def_skeleton)\n",
        "    ok = sum(1 for x in parsed if isinstance(x, dict))\n",
        "    return {\"raw\": raws, \"parsed\": parsed, \"ok\": ok, \"total\": len(raws)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 1, è§£ææˆåŠŸ: 1, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
            "  ğŸ” Summarizeç»Ÿè®¡ -> æ®µè½æ¥æºåˆ—: content, æ®µè½æ€»æ•°: 1, è§£ææˆåŠŸ: 0, å«çœç•¥å·: 0, ä¿¡å·=0æ¡æ•°: 0\n",
            "å¾®è°ƒè§£æç‡: 1/1\n",
            "åŸå§‹è§£æç‡: 1/1\n",
            "===== æ®µè½ 1 =====\n",
            "â€” å¾®è°ƒåŸæ–‡:\n",
            "{\"reaction_summary\": {\"reaction_type\": \"polymerization\", \"reactants\": [{\"name\": \"BA\", \"role\": \"catalyst\"}], \"products\": [{\"name\": null, \"yield_optimal\": 82.0, \"unit\": \"%\"}], \"conditions\": [{\"type\": \"temperature\", \"value\": \"80 Â°C\"}, {\"type\": \"residence_time\", \"value\": null}, {\"type\": \"flow_rate_total\", \"value\": \"0.1 mL/min\"}, {\"type\": \"pressure\", \"value\": null}], \"reactor\": {\"type\": \"coil\", \"inner_diameter\": \"0.5 mm\"}, \"metrics\": {\"conversion\": 82, \"yield\": 82.0, \"selectivity\": null, \"unit\": \"%\"}}}\n",
            "â€” åŸå§‹åŸæ–‡:\n",
            "{\"reaction_summary\": {\"reaction_type\": null, \"reactants\": [], \"products\": [], \"conditions\": [], \"reactor\": {\"type\": null, \"inner_diameter\": null}, \"metrics\": {\"conversion\": null, \"yield\": null, \"selectivity\": null, \"unit\": \"%\"}}}\n",
            "â€” å¾®è°ƒè§£æ:\n",
            "{\n",
            "  \"reaction_summary\": {\n",
            "    \"reaction_type\": \"polymerization\",\n",
            "    \"reactants\": [\n",
            "      {\n",
            "        \"name\": \"BA\",\n",
            "        \"role\": \"catalyst\"\n",
            "      }\n",
            "    ],\n",
            "    \"products\": [\n",
            "      {\n",
            "        \"name\": null,\n",
            "        \"yield_optimal\": 82.0,\n",
            "        \"unit\": \"%\"\n",
            "      }\n",
            "    ],\n",
            "    \"conditions\": [\n",
            "      {\n",
            "        \"type\": \"temperature\",\n",
            "        \"value\": \"80 Â°C\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"residence_time\",\n",
            "        \"value\": null\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"flow_rate_total\",\n",
            "        \"value\": \"0.1 mL/min\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"pressure\",\n",
            "        \"value\": null\n",
            "      }\n",
            "    ],\n",
            "    \"reactor\": {\n",
            "      \"type\": \"coil\",\n",
            "      \"inner_diameter\": \"0.5 mm\"\n",
            "    },\n",
            "    \"metrics\": {\n",
            "      \"conversion\": 82,\n",
            "      \"yield\": 82.0,\n",
            "      \"selectivity\": null,\n",
            "      \"unit\": \"%\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "â€” åŸå§‹è§£æ:\n",
            "{\n",
            "  \"reaction_summary\": {\n",
            "    \"reaction_type\": null,\n",
            "    \"reactants\": [],\n",
            "    \"products\": [],\n",
            "    \"conditions\": [],\n",
            "    \"reactor\": {\n",
            "      \"type\": null,\n",
            "      \"inner_diameter\": null\n",
            "    },\n",
            "    \"metrics\": {\n",
            "      \"conversion\": null,\n",
            "      \"yield\": null,\n",
            "      \"selectivity\": null,\n",
            "      \"unit\": \"%\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# è¿è¡Œä¸¤ä¸ªæ¨¡å‹ï¼Œç»Ÿè®¡è§£æç‡å¹¶é€æ®µå¯¹æ¯”\n",
        "ft_res  = run_summarize_in_memory(pipeline_ft_manual, PARAS)\n",
        "base_res = run_summarize_in_memory(pipeline_base_manual, PARAS)\n",
        "\n",
        "print(f\"å¾®è°ƒè§£æç‡: {ft_res['ok']}/{ft_res['total']}\")\n",
        "print(f\"åŸå§‹è§£æç‡: {base_res['ok']}/{base_res['total']}\")\n",
        "\n",
        "import itertools\n",
        "\n",
        "def to_str(x):\n",
        "    import json\n",
        "    try:\n",
        "        return json.dumps(x, ensure_ascii=False, indent=2)\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "for i, (r1, r2, p1, p2) in enumerate(zip(ft_res['raw'], base_res['raw'], ft_res['parsed'], base_res['parsed']), 1):\n",
        "    print(f\"===== æ®µè½ {i} =====\")\n",
        "    print(\"â€” å¾®è°ƒåŸæ–‡:\")\n",
        "    print(r1)\n",
        "    print(\"â€” åŸå§‹åŸæ–‡:\")\n",
        "    print(r2)\n",
        "    print(\"â€” å¾®è°ƒè§£æ:\")\n",
        "    print(to_str(p1))\n",
        "    print(\"â€” åŸå§‹è§£æ:\")\n",
        "    print(to_str(p2))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å‡†å¤‡åŠ è½½: /Users/zhaowenyuan/Projects/FCPDExtractor/models/My_Finetuned_Model_Q4_K_M_para2json_mixed_final_robust.gguf\n",
            "â—æœªæ‰¾åˆ° My_Finetuned_Model_Q4_K_M_para2json_mixed_final_robust.ggufï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦å­˜åœ¨äº /Users/zhaowenyuan/Projects/FCPDExtractor/models\n"
          ]
        }
      ],
      "source": [
        "# é€šç”¨ä»»åŠ¡ç›´æµ‹ï¼šæŒ‡å®š GGUFï¼ˆMy_Finetuned_Model_Q4_K_M_para2json_mixed_final_robust.ggufï¼‰+ çº¯ JSON å›ç­”\n",
        "from gpt4all import GPT4All\n",
        "import json as _json, re as _re\n",
        "from pathlib import Path\n",
        "\n",
        "TEST_MODEL = \"My_Finetuned_Model_Q4_K_M_para2json_mixed_final_robust.gguf\"\n",
        "model_path = (MODELS_DIR / TEST_MODEL)\n",
        "print(f\"å‡†å¤‡åŠ è½½: {model_path}\")\n",
        "if not model_path.exists():\n",
        "    print(f\"â—æœªæ‰¾åˆ° {TEST_MODEL}ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦å­˜åœ¨äº {MODELS_DIR}\")\n",
        "else:\n",
        "    # ä½¿ç”¨è¾ƒå¤§çš„ä¸Šä¸‹æ–‡ï¼Œç¦ç”¨ä¸‹è½½\n",
        "    test_model = GPT4All(str(TEST_MODEL), model_path=str(MODELS_DIR), allow_download=False, n_ctx=2048)\n",
        "\n",
        "    def _extract_json_max_block(s: str) -> str:\n",
        "        s = s.strip().replace('```json','').replace('```','')\n",
        "        # å–æœ€å¤§ä¸€æ®µ {} å—\n",
        "        start = None\n",
        "        depth = 0\n",
        "        best = \"\"\n",
        "        for i, ch in enumerate(s):\n",
        "            if ch == '{':\n",
        "                if depth == 0:\n",
        "                    start = i\n",
        "                depth += 1\n",
        "            elif ch == '}':\n",
        "                if depth > 0:\n",
        "                    depth -= 1\n",
        "                    if depth == 0 and start is not None:\n",
        "                        seg = s[start:i+1]\n",
        "                        if len(seg) > len(best):\n",
        "                            best = seg\n",
        "                        start = None\n",
        "        return best if best else s\n",
        "\n",
        "    # æç®€ç³»ç»Ÿ + ç”¨æˆ·æŒ‡ä»¤ï¼ˆä»… JSONã€ä»¥ { å¼€å¤´ï¼‰\n",
        "    system = \"You output ONLY valid JSON. Start with '{' and end with '}'. No explanations.\"\n",
        "    user = (\n",
        "        \"è¯·ç”¨ä¸€ä¸ªJSONå¯¹è±¡å›ç­”ï¼š\\n\"\n",
        "        \"- å­—æ®µ: name, definition, mime_type, example\\n\"\n",
        "        \"- ä»…æ ¹æ®å¸¸è¯†ç®€è¦å®šä¹‰ JSON (JavaScript Object Notation)ï¼Œç»™å‡ºä¸€ä¸ªç®€å•ç¤ºä¾‹å¯¹è±¡\\n\"\n",
        "        \"- åªè¾“å‡º JSONï¼Œä¸è¦å¤šä½™æ–‡å­—\\n\"\n",
        "        \"- å­—æ®µå«ä¹‰ï¼šname=\\\"JSON\\\"ï¼Œdefinition=ä¸€å¥è¯å®šä¹‰ï¼Œmime_type=\\\"application/json\\\"ï¼Œexample ä¸ºä¸€ä¸ªåŒ…å«2-3ä¸ªé”®å€¼å¯¹çš„å°å¯¹è±¡\\n\"\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        f\"{system}\\n\\nUser:\\n{user}\\nAssistant:\\n\"  # Plain æ¨¡æ¿\n",
        "        '{ \"name\": \"JSON\", \"definition\": '\n",
        "    )\n",
        "\n",
        "    raw = test_model.generate(prompt=prompt, max_tokens=512, temp=0.0)\n",
        "    # è£å‰ªå¹¶è½»æ¸…æ´—\n",
        "    jtxt = _extract_json_max_block(raw)\n",
        "    jtxt = _re.sub(r'(?<!\")(?P<num>\\d+(?:\\.\\d+)?)\\s*%', r'\\g<num>', jtxt)\n",
        "\n",
        "    print(\"--- åŸå§‹è¾“å‡º ---\")\n",
        "    print(raw)\n",
        "    print(\"\\n--- æœ€å¤§èŠ±æ‹¬å·å— ---\")\n",
        "    print(jtxt)\n",
        "\n",
        "    try:\n",
        "        parsed = _json.loads(jtxt)\n",
        "        print(\"\\nâœ… JSON è§£ææˆåŠŸï¼š\")\n",
        "        print(_json.dumps(parsed, ensure_ascii=False, indent=2))\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ JSON è§£æå¤±è´¥: {e}\")\n",
        "        print(\"è¯·å°è¯•ï¼š\\n- ç¡®è®¤ GGUF åˆå¹¶äº† LoRA å¹¶ä¸åº•æ¨¡/Tokenizer åŒ¹é…\\n- é™ä½æŒ‡ä»¤é•¿åº¦ï¼›ä¿æŒèµ·ç¬” '{'ï¼›å°è¯•å°† temp=0.1 æˆ–å¢åŠ  max_tokens=1024\\n- æˆ–æ”¹ç”¨ HF æƒé‡ç›´æ¥æ¨ç†éªŒè¯å¾®è°ƒæœ‰æ•ˆæ€§åå†å¯¼å‡º GGUF\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å¾®è°ƒç›´æ¨å®Œæˆã€‚æ¡ç›®æ•°: 1\n",
            "===== ç›´æ¨æ®µè½ 1 =====\n",
            "â€” æ¸…æ´—åJSON:\n",
            "{\"reaction_summary\": {\"reaction_type\": \"null\"}, \"reactants\": [{\"name\": \"null\", \"role\": \"catalyst\"}], \"products\": [], \"conditions\": [{\"type\": \"temperature\", \"value\": \"80 Â°C\"}], \"reactor\": {\"type\": \"coil\", \"inner_diameter\": \"0.5 mm\"}, \"metrics\": {\"conversion\": null, \"yield\": 82, \"selectivity\": null, \"unit\": \"%\"}}\n",
            "â€” è§£æç»“æœ:\n",
            "{\n",
            "  \"reaction_summary\": {\n",
            "    \"reaction_type\": \"null\"\n",
            "  },\n",
            "  \"reactants\": [\n",
            "    {\n",
            "      \"name\": \"null\",\n",
            "      \"role\": \"catalyst\"\n",
            "    }\n",
            "  ],\n",
            "  \"products\": [],\n",
            "  \"conditions\": [\n",
            "    {\n",
            "      \"type\": \"temperature\",\n",
            "      \"value\": \"80 Â°C\"\n",
            "    }\n",
            "  ],\n",
            "  \"reactor\": {\n",
            "    \"type\": \"coil\",\n",
            "    \"inner_diameter\": \"0.5 mm\"\n",
            "  },\n",
            "  \"metrics\": {\n",
            "    \"conversion\": null,\n",
            "    \"yield\": 82,\n",
            "    \"selectivity\": null,\n",
            "    \"unit\": \"%\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# å¾®è°ƒç›´æ¨ï¼ˆä¸¥æ ¼æç¤ºè¯+æ¸…æ´—+ä¸€æ¬¡é‡è¯•ï¼‰ï¼šç¦æ­¢çœç•¥å·ã€å…è®¸æ—  role åŒ–å­¦åï¼ˆrole=nullï¼‰ã€ä¸¥æ ¼æ‹·è´å­—ç¬¦ä¸²å€¼\n",
        "import json as _json, re as _re\n",
        "\n",
        "_strict_system = \"You output ONLY valid JSON. No explanations, no markdown, no comments.\"\n",
        "_strict_user = (\n",
        "    \"Only use THIS paragraph; output ONLY one JSON object.\\n\"\n",
        "    \"Keys: reaction_summary.reaction_type, reactants[{name,role}], \"\n",
        "    \"products[{name,yield_optimal,unit}], conditions[{type,value}], \"\n",
        "    \"reactor{type,inner_diameter}, metrics{conversion,yield,selectivity,unit}.\\n\"\n",
        "    \"Condition types: temperature,residence_time,flow_rate_total,pressure.\\n\"\n",
        "    \"Copy condition values verbatim (e.g., '160 Â°C','21 min'). No examples/explanations/markdown.\\n\"\n",
        "    \"Start with '{' and end with '}'.\"\n",
        ")\n",
        "\n",
        "# è§£æå¤±è´¥æ—¶çš„äºŒæ¬¡æ›´ä¸¥æ ¼æç¤º\n",
        "_strict_user_retry = (\n",
        "    \"Return ONLY valid JSON for THIS paragraph. No examples, no explanations, no code fences.\\n\"\n",
        "    \"Start with '{' and end with '}'. If any extra text appears, the answer is invalid.\\n\"\n",
        "    \"Keys must be exactly: reaction_summary.reaction_type, reactants[{name,role}], \"\n",
        "    \"products[{name,yield_optimal,unit}], conditions[{type,value}], reactor{type,inner_diameter}, \"\n",
        "    \"metrics{conversion,yield,selectivity,unit}. Values not present must be null or empty arrays.\"\n",
        ")\n",
        "\n",
        "def _extract_json_block(s: str) -> str:\n",
        "    s = s.strip().replace('```json','').replace('```','')\n",
        "    l, r = s.find('{'), s.rfind('}')\n",
        "    if l != -1 and r != -1 and r > l:\n",
        "        return s[l:r+1]\n",
        "    return s\n",
        "\n",
        "# è½»æ¸…æ´—ï¼šå»ç¤ºä¾‹è¯´æ˜/ç™¾åˆ†å·/æ¡ä»¶é”®åå¤§å°å†™/çœç•¥å·\n",
        "_def_cond_key_map = {\n",
        "    'Temperature': 'temperature',\n",
        "    'Residence_time': 'residence_time',\n",
        "    'Flow_rate_total': 'flow_rate_total',\n",
        "    'Pressure': 'pressure',\n",
        "}\n",
        "\n",
        "def _sanitize_strict_json(txt: str) -> str:\n",
        "    s = txt\n",
        "    # å»ç¤ºä¾‹æ®µ\n",
        "    s = _re.sub(r'(?is)\\bExample\\s+Input:.*$', '', s).strip()\n",
        "    s = _re.sub(r'(?is)\\bExample\\s+Output:.*$', '', s).strip()\n",
        "    # ä»…ä¿ç•™æœ€å¤§èŠ±æ‹¬å·å—\n",
        "    s = _extract_json_block(s)\n",
        "    # 97% -> 97ï¼ˆä»…æœªåŠ å¼•å·çš„ç™¾åˆ†æ•°ï¼‰\n",
        "    s = _re.sub(r'(?<!\")(?P<num>\\d+(?:\\.\\d+)?)\\s*%', r'\\g<num>', s)\n",
        "    # ç»Ÿä¸€ conditions.type é”®åå¤§å°å†™\n",
        "    for k,v in _def_cond_key_map.items():\n",
        "        s = s.replace(f'\"{k}\"', f'\"{v}\"')\n",
        "    # ç¦ç”¨çœç•¥å· â†’ null\n",
        "    s = _re.sub(r':\\s*(\"?\\.\\.\\.\"?|â€¦)(\\s*[,}\\]])', r': null\\2', s)\n",
        "    return s\n",
        "\n",
        "ft_direct_raw = []\n",
        "ft_direct_parsed = []\n",
        "\n",
        "for para in PARAS:\n",
        "    ctx = str(para)\n",
        "    # å¼ºåˆ¶ä½¿ç”¨ Llama3.1 chat æ¨¡æ¿ä»¥è´´è¿‘å¾®è°ƒåˆ†å¸ƒ\n",
        "    # prompt = pipeline_ft_manual._create_llama31_chat_prompt(_strict_system, _strict_user, ctx)\n",
        "    # model = pipeline_ft_manual._get_stage_model('summarize')\n",
        "    # raw = pipeline_ft_manual._safe_generate(model, prompt, max_tokens=1024, temp=0.2)\n",
        "\n",
        "    prompt = pipeline_ft_manual._create_llama31_chat_prompt(_strict_system, _strict_user, ctx) + \"{\"\n",
        "    model = pipeline_ft_manual._get_stage_model('summarize')\n",
        "    raw = pipeline_ft_manual._safe_generate(model, prompt, max_tokens=2048, temp=0.1)\n",
        "    \n",
        "    jtxt = _extract_json_block(raw)\n",
        "    cleaned = _sanitize_strict_json(jtxt)\n",
        "    ft_direct_raw.append(cleaned)\n",
        "    obj = None\n",
        "    try:\n",
        "        obj = _json.loads(cleaned)\n",
        "    except Exception:\n",
        "        # äºŒæ¬¡æ›´ä¸¥æ ¼é‡è¯•\n",
        "        prompt2 = pipeline_ft_manual._create_llama31_chat_prompt(_strict_system, _strict_user_retry, ctx)\n",
        "        raw2 = pipeline_ft_manual._safe_generate(model, prompt2, max_tokens=700, temp=0.0)\n",
        "        cleaned2 = _sanitize_strict_json(raw2)\n",
        "        try:\n",
        "            obj = _json.loads(cleaned2)\n",
        "            ft_direct_raw[-1] = cleaned2\n",
        "        except Exception:\n",
        "            obj = None\n",
        "            ft_direct_raw[-1] = cleaned2\n",
        "    ft_direct_parsed.append(obj)\n",
        "\n",
        "print('å¾®è°ƒç›´æ¨å®Œæˆã€‚æ¡ç›®æ•°:', len(ft_direct_parsed))\n",
        "for i, (r, p) in enumerate(zip(ft_direct_raw, ft_direct_parsed), 1):\n",
        "    print(f\"===== ç›´æ¨æ®µè½ {i} =====\")\n",
        "    print('â€” æ¸…æ´—åJSON:')\n",
        "    print(r)\n",
        "    print('â€” è§£æç»“æœ:')\n",
        "    try:\n",
        "        print(_json.dumps(p, ensure_ascii=False, indent=2))\n",
        "    except Exception:\n",
        "        print(p)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ossextractor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
